\subsection{Further properties of normed spaces}

\begin{question}
    Show that $c \subset \ell^\infty$ is a vector subspace of $\ell^\infty$ and so is $c_0$, the space of all sequences of scalars converging to zero.
    \label{section2.3-1}
\end{question}
\begin{proof}
    Recall that $c \subset \ell^\infty$ is the space of all convergent sequences $(x_n)$ with the metric induced from the $\ell^\infty$ space. To show that $c$ is a vector space, we need to ensure that all properties of addition and multiplication hold. First, for addition we wish to ensure that the sum of two convergent sequences is convergent, i.e if $x_n \rightarrow x$ and $y_n \rightarrow y$, then
    \[0 \leq \lim_{n \rightarrow \infty}\norm{(x_n + y_n) - (x+y)} \leq \lim_{n \rightarrow \infty} \norm{x_n -x} + \lim_{n \rightarrow \infty} \norm{y_n - y} = 0\]
    and hence, $x_n + y_n \rightarrow x + y$. Clearly, the commutative and associative properties of addition hold. Also, the additive identity is simply the constant zero sequence, which is convergent.

    For multiplication, if $x_n \rightarrow x$, then
    \[\lim_{n \rightarrow \infty} \norm{\alpha x_n - \alpha x} = \abs{\alpha} \lim_{n \rightarrow \infty} \norm{x_n -x} = 0\]
    and hence, $\alpha x_n \rightarrow \alpha x$. The associativity for multiplication holds, and the multiplicative identity is simply the scalar $1$.
    
    In a similar fashion, if $x_n \rightarrow 0$ and $y_n \rightarrow 0$, then $x_n + y_n \rightarrow 0$, and the addition property satisfies associativity and commutativity. Further, the zero vector is the additive identity, and since the zero  vector converges to $0$, it belongs to $c_0$. The multiplication of a sequence $x_n \rightarrow 0$ does not change any convergence properties, and the multiplicative identity continues to remain the scalar $1$. 
\end{proof}

\begin{question}
    Show that $c_0$ is a closed subspace of $\ell^\infty$, so that $c_0$ is complete.
    \label{section2.3-2}
\end{question}
\begin{proof}
   Let $(x_1 , x_2 , \ldots )$ be a sequence converging to $x = (\xi_1  , \xi_2 , \ldots)$. Each term $x_i = (\xi^{(i)}_1 , \xi^{(i)}_2 , \ldots)$ it itself a sequence that converges to zero. Thus, we have that for some $\epsilon \g 0$, $\exists N_1(\epsilon)$ such that for $n \g  N(\epsilon)$
   \[d(x_n , 0) \l \epsilon.\]
   Now, since $(x_1 , x_2 ,\ldots)$ also converges to $x$ under the metric induced by the $\ell^\infty$ space, so we have that for some $\epsilon \g 0$, $\exists N_2(\epsilon)$ such that for $n \g N_2(\epsilon)$, we have
   \[d(x_n , x) = \sup_{i} \abs{\xi^{(n)}_i  -\xi_i} \l \epsilon \implies  \abs{\xi^{(n)}_i  -\xi_i} \l \epsilon \; \forall i.\]
   We wish to show that the limit point $x = (\xi_1  , \xi_2 , \ldots)$ also converges to zero, so that $x \in c_0$. Thus, we have that for some $\epsilon \g 0$ and $N(\epsilon) = \max\{N_1(\epsilon) , N_2(\epsilon)\}$, for all $n \g N(\epsilon)$, we have
   \[d(\xi_i , 0) \leq d(\xi_i , \xi^{(n)}_i) + d(\xi^{(n)}_i , 0) \leq 2\epsilon.\]
   Thus, $x \in c_0$, and hence the space is closed, which in turn also means, the space is complete.
\end{proof}

\begin{question}
    In $\ell^\infty$, let $Y$ be the subset of ll sequences with only finitely many non-zero terms. Show that $Y$ is a subspace of $\ell^\infty$ by not a closed subspace.
    \label{section2.3-3}
\end{question}
\begin{proof}
    Consider the sequence of sequences $(x_1 , x_2 , \ldots)$ where 
    \[x_i = \left(1 , \frac{1}{2} , \ldots , \frac{1}{i} , 0 , 0 , \ldots \right)\]
    Then, this sequence converges to 
    \[\left(1 , \frac{1}{2} , \ldots , \frac{1}{n} , \frac{1}{n+1} , \ldots \right)\]
    which does not belong to $Y$.
\end{proof}

\begin{question}
    Show that in a normed space $X$, vector addition and multiplication by scalars are continuous operations with respect to the norm, i.e, the mappings defined by $(x,y) \mapsto x + y$ and $(\alpha , x) \mapsto \alpha x$ are continuous.
    \label{section2.3-4}
\end{question}
\begin{proof}
    Recall the definition of continuity of a map $T : X \mapsto Y$ at a point $x_0$: for some $\epsilon \g 0$, $\exists \delta \g 0$ such that $\norm{x - x_0} \l \delta \implies \norm{Tx - Tx_0} \l \epsilon$.

    First, for addition, consider the map $T : X \times X \mapsto X$ such that $T(x,y) = x + y$. Then, we show that 
    \[\norm{(x,y) - (x_0 , y_0)} \l \delta \implies \norm{T(x,y) - T(x_0 , y_0)} \l \epsilon.\]
    First, we have
    \[\norm{(x,y) - (x_0, y_0)} = \norm{(x - x_0 , y-y_0)} \l \norm{x - x_0} + \norm{y_0} \l \delta.\]
    Then, 
    \[\norm{T(x,y) - T(x_0 , y_0)} = \norm{x + y - x_0 - y_0} \leq \norm{x - x_0} + \norm{y - y_0} \leq \delta.\]
    Thus, choosing $\delta = \epsilon$ shows that addition is a continuous map.

    Now, consider the map $T : K \times X \mapsto X$ such that $T(\alpha , x) = \alpha x$. Now, we show that
    \[\norm{(\alpha , x) - (\alpha_0 , x_0)} \l \delta \implies \norm{T(\alpha , x) - T(\alpha_0 , x_0)} \l \epsilon.\]
    First, we have that
    \[\norm{(\alpha , x) - (\alpha_0 , x_0)} = \norm{(\alpha - \alpha_0 , x - x_0)} = \norm{\alpha - \alpha_0} + \norm{x - x_0} \l \delta\]
    Now, 
    \[\norm{T(\alpha , x) - T(\alpha_0 , x_0)} = \norm{\alpha x - \alpha_0 x_0} = \norm{(\alpha - \alpha_0)x + \alpha_0(x - x_0)} \leq \norm{\alpha - \alpha_0} \norm{x} + \norm{\alpha_0} \norm{x - x_0}.\]
    Now, setting $\norm{\alpha - \alpha_0} \l \delta$ and $\norm{x - x_0} \l \delta$, we get
    \[\norm{T(\alpha , x) - T(\alpha_0 , x_0)} \l \delta(\norm{x_0} + \delta) + \norm{\alpha_0}\delta \l \epsilon.\]
    Thus, assuming $\delta \l 1$, we get
    \[\delta^2 + \delta(\norm{x_0} + \norm{\alpha_0}) \l \delta(\norm{x_0} + \norm{\alpha_0} + 1) \l \epsilon,\] 
    and solving for $\delta$ gives us
    \[\delta = \min \left\{\frac{\epsilon}{2 ( \norm{x_0} + \norm{a_0}} , 1 \right\}.\]
    Thus, the multiplication map is also continuous.
\end{proof}

\begin{question}
    Show that $x_n \rightarrow x$ and $y_n \rightarrow y$ implies $x_n + y_n \rightarrow x + y$. Show that $\alpha_n \rightarrow \alpha$ and $x_n \rightarrow x$ implies $\alpha_n x_n \rightarrow \alpha x$.
    \label{section2.3-5}
\end{question}
\begin{proof}
    Since $x_n \rightarrow x$ and $y_n \rightarrow y$, we have that
    \[\lim_{n \rightarrow \infty} \norm{x_n - x} = 0 \text{ and }\lim_{n \rightarrow \infty} \norm{y_n - y} = 0,\]
    and hence,
    \[0 \leq \lim_{n \rightarrow \infty} \norm{(x_n + y_n) - (x+y)} \leq \lim_{n \rightarrow \infty} \norm{x_n - x} + \lim_{n \rightarrow \infty} \norm{x_n - x} = 0\]
    and hence, $x_n + y_n \rightarrow x + y$.
    Similarly, since $\alpha_n \rightarrow \alpha$ and $x_n \rightarrow x$, we have
    \[\lim_{n \rightarrow \infty} \abs{\alpha_n - \alpha} = 0 \text{ and } \lim_{n \rightarrow \infty} \norm{x_n - x} = 0,\]
    since $\alpha$ is a part of the scalar field. Thus, 
     \[\lim_{n \rightarrow \infty} \norm{\alpha_n x_n - \alpha x} = \lim_{n \rightarrow \infty} \norm{\alpha_n (x_n - x)} + \lim_{n \rightarrow \infty} \norm{(\alpha_n - \alpha)x} =  \lim_{n \rightarrow \infty} \abs{\alpha_n}\norm{x_n - x} + \lim_{n \rightarrow \infty} \abs{\alpha_n - \alpha} \norm{x} = 0.\]
\end{proof}

\begin{question}
    Show that the closure $\overline{Y}$ of a subspace ${Y}$ of a normed space $X$ is again a vector space.
    \label{section2.3-6}
\end{question}
\begin{proof}
    First, since $Y$ is a subspace, for any $x , y \in Y$, we have
    \[\alpha x + \beta y \in Y\].
    Now, consider $\overline{Y}$, which consists of $Y$ and the accumulation points of $Y$. If the accumulation points of $Y$ belong to $Y$ itself, we are done. However, say $x$ and $y$ are two accumulation points which do not belong to $Y$. Then, there exist sequences $(x_n)$ and $(y_n)$ in $Y$ that converge to $x$ and $y$ respectively. From \ref{section2.3-5}, we have that $\alpha x_n + \beta y_n \rightarrow \alpha x + \beta y$ and hence, $\alpha x + \beta y$ is also an accumulation point. Thus, $\alpha x + \beta y$ also belongs to the set of accumulation points. One question that should arise is what if one point $y \in Y$ and $x \notin Y$ but $x$ is an accumulation point. In such a case, the constant sequence $(y,y\ldots,) \rightarrow y$ and another sequence $x_n \rightarrow x$, and hence, $\alpha x + \beta y$ would also be an accumulation point. Thus, the set $\overline{Y}$ is also a subspace.
\end{proof}

\begin{question}
    Show that the convergence of $\norm{y_1} + \norm{y_2} + \norm{y_3} \ldots$ may not imply convergence of $y_1 + y_2 + y_3+ \ldots$.
    \label{section2.3-7}
\end{question}
\begin{proof}
    We shall make use of the hint given in the question. Consider the space in \ref{section2.3-3}, a space of sequences here each sequence consists of finitely many non-zero terms. Consider the sequence $(y_1 , y_2 , \ldots)$, where $y_n = (\eta_j^{(n)})$ and 
    \[\eta_j^{(n)} = \begin{cases}
        \frac{1}{n^2} & j = n
        \\
        0 & j \neq n
    \end{cases}.\]
    In such a case, we know that
    \[\sum_{i=1}^\infty \norm{y_i} = \sum_{i=1}^\infty \frac{1}{i^2} = \frac{\pi^2}{6}.\]
    However, consider the series $y_1 + y_2 + y_3 + \ldots$. Consider the partial sum $s_n$:
    \[s_n = \left(1 , \frac{1}{4} , \ldots , \frac{1}{n^2} , 0 ,0 , \ldots \right).\]
    This sequence of partial sums will converge to a term which will not have finitely many non-zero terms and hence, does not converge in the space.
\end{proof}

\begin{question}
    If in a normed space $X$, if absolute convergence of any series always implies convergence of that series, show that $X$ is complete.
    \label{section2.3-8}
\end{question}
\begin{proof}
    Let $(x_n)$ be a sequence that converges absolutely, and hence, also converges. Since it converges absolutely, we know that the partial sums of the norms converge, and hence, the sequence of the partial sums of the norms is Cauchy. Let $s_n$ denote the $n^{th}$ sequence of partial sums. Then, for some $\epsilon \g 0$, there exists $N(\epsilon)$ such that for $m,n \g N(\epsilon)$, we have
    \[\norm{s_m - s_n} = \norm{\sum_{i=n+1}^m \norm{x_i}} \leq \sum_{i=n+1}^m \norm{x_i} \leq \epsilon.\]
    Note that the final expression is exactly the partial sums of the sequence $(x_1 , x_2 , \ldots)$, 
    \[\norm{s_m - s_n} = \norm{\sum_{i=1}^n x_i - \sum_{i=1}^m x_i} = \norm{\sum_{i=n+1}^{m} x_i} \l \sum_{i=n+1}^{m} \norm{x_i} \l \epsilon\]
    and hence, the sequence of partial sums is Cauchy. Since absolute convergence implies convergence, the Cauchy sequence will converge if and only if the space is complete.
\end{proof}

\begin{question}
    Show that in a Banach space, an absolutely convergent series is convergent.
    \label{section2.3-9}
\end{question}
\begin{proof}
    The answer to this is similar to the last one. A Banach space is a complete normed space. Suppose $(x_n)$ is an absolutely convergent series. Then, the sequence of partial sums of the norm is convergent, and hence, Cauchy. Thus, representing the partial sum as $s_n$, we have
    \[\norm{s_m - s_n} = \norm{\sum_{i=n+1}^m \norm{x_i}} \leq \sum_{i=n+1}^m \norm{x_i} \leq \epsilon.\]
    This is exactly the difference of the partial sums of the series $(x_n)$ and hence, shows that the sequence of partial sums of $(x_n)$ is Cauchy. Since it is a Banach space, Cauchy sequences converge, and hence, the sequence of partial sums converges, and hence, the series $(x_n)$ 
\end{proof}

\begin{question}
    Show that if a normed space has a Schauder basis, it is separable.
    \label{section2.3-10}
\end{question}
\begin{proof}
    Recall the definition of a Schauder basis: a sequence $(e_n)$ is called a Schauder basis if for every $x \in X$, there exists a unique sequence of scalars $\alpha_i$ such that
    \[\lim_{n \rightarrow \infty} \sum_{i=1}^n \alpha_i e_i = x.\]
    To show that $X$ is separable, we need to show it has a countable dense subset. Let $Y$ be a subset. Let $x \in Y$ be such that
    \[\lim_{n \rightarrow \infty} \sum_{i=1}^n \alpha_i e_i = x.\]
    Now, since $\alpha_i$ belong to the underlying field $K$, and hence, there exists a sequence $\beta_i$ such that
    \[\abs{\alpha_i - \beta_i} \l \epsilon.\]
    Let us denote some point $y$ such that
    \[\lim_{n \rightarrow \infty} \sum_{i=1}^n \beta_i e_i = y.\]
    Then, we have that for some $\epsilon \g 0$, $\exists N(\epsilon)$ such that for $n \g N(\epsilon)$, we have
    \begin{align*}
        \norm{x - y} &\leq \norm{x - \sum_{i=1}^n \alpha_i e_i} + \norm{y - \sum_{i=1}^n \beta_i e_i} + \norm{\sum_{i=1}^n (\alpha_i - \beta_i) e_i}
        \\
        &\leq \epsilon + \epsilon + n\epsilon \norm{e_i} 
        \\
        &\leq \epsilon^\prime
    \end{align*}
    and hence, for every $x$ there exists some point $y$ such that $x \in B(y , \epsilon)$. Thus, the subset $Y$ is dense.
\end{proof}

\begin{question}
    Show that $(e_n)$ where $e_n = (\delta_{nj})$, is a Schauder basis for $\ell^p$, where $1 \leq p \l \infty$.
    \label{section2.3-11}
\end{question}
\begin{proof}
    Let $x = (\xi_1 , \xi_2 , \ldots) \in \ell^p$ such that 
    \[\norm{x}_p = \left(\sum_{i=1}^\infty \abs{\xi_i}^p \right)^{1/p} \l \infty.\]
    In other words, $\left(\sum_{i=1}^\infty \abs{\xi_i}^p \right)^{1/p}$ converges, and hence, for some $\epsilon \g 0$, there exists $N(\epsilon)$ such that for all $n \g N(\epsilon)$, we have
    \[\left(\sum_{i=n+1}^\infty \abs{\xi_i}^p \right)^{1/p} \l \epsilon.\]
    Now, consider the sequence $(\delta_{nj})$ with the coefficients $\xi_1 , \xi_2 \ldots$. Represent
    \[x_n = \sum_{i=1}^n \xi_i \delta_{ni}.\]
    Then, we have
    \[\norm{x - x_n} = \norm{\sum_{i = n+1}^\infty \xi_i \delta_{ni}} \leq \sum_{i=n+1}^\infty \abs{\xi_i} \norm{\delta_{ni}} \leq \epsilon.\]
    and hence, $x_n \rightarrow x$. Thus, it is a Schauder basis.
\end{proof}

\begin{question}
    A seminorm on a vector space $X$ is a mapping $p : X \mapsto \R$ satisfying (N1), (N3), (N4). Show that $p(0) = 0$ and $\abs{p(y) - p(x)} \l p(y-x).$ This also means that if $p(x) = 0 \implies x = 0$, then it is a norm.
    \label{section2.3-12}
\end{question}
\begin{proof}
    We are given that $p$ satisfies the following properties:
    \begin{enumerate}
        \item $p \geq 0$
        \item $p(\alpha x) = \abs{\alpha}p(x)$.
        \item $P(x + y) \leq p(x) + p(y).$
    \end{enumerate}
    Now, substituting $\alpha = 0$ gives us $p(0) = 0$. Also, we have
        \[p(x) \leq p(x-y) + p(y) \implies p(x) - p(y) \leq p(x-y).\]
        Similarly, we have
        \[p(y) \leq p(y-x) + p(x) = \abs{-1}p(x-y) + p(x) \implies p(y) - p(x) \leq p(x-y).\]
        Combining both these results, we get
        \[\abs{p(x) - p(y)} \leq p(x-y).\]
\end{proof}

\begin{question}
    Show that in \ref{section2.3-12}, the elements $x \in X$ such that $p(x) = 0$ form a subspace $N$ of $X$ and a norm on $X/N$ is defined by $\norm{\hat{x}}_0 = p(x)$ where $x \in \hat{x}$ and $\hat{x} \in X/N$.
    \label{section2.3-13}
\end{question}
\begin{proof}
    Let $x , y \in N$ such that $p(x) = p(y) = 0$. We wish to show that $\alpha x + \beta y \in N$. This will only happen if $p(\alpha x + \beta y) = 0$.
    \[p(\alpha x + \beta y) \leq p(\alpha x) + p(\beta y) = \abs{\alpha} p(x) + \abs{\beta} p(y) = 0\]
    and thus, $\alpha x + \beta y \in N$. Hence, N is a subset. Recall the definitions of a coset and a quotient space as follows: for some element $x$, we define the coset w.r.t $Y$ as
    \[x + Y = \{x + y \mid  y \in Y\}.\]
    These distinct cosets partition $X$, and the space of these cosets is called the quotient space and is represented by $X/Y$.

    Now, to show that $\norm{\hat{x}}_0 = p(x)$ is a norm on $X/N$, we have to show that $p(x)$ satisfies all properties of a norm on $X/N$. From \ref{section2.3-13}, we have that $p(x)$ satisfies non-negativity, scalar multiplication, and the triangle inequality. We have also shown that $p(0) = 0$. Thus, to show that $p(x)$ is a norm, we wish to show that $p(x)  = 0 \implies x = 0$. Let $\hat{x}$ define a coset and $x \in \hat{x}$. Then, 
    \[\hat{x} = \{x + n \mid n \in N\}.\]
    We first show that $p(x) = p(x + n)$ for any $n \in N$. We have that
    \[p(x) = p((x+n) - n) \leq p(x+n) + p(n) \leq p(x) + p(n) = p(x)\]
    Thus, all the inequalities have to be equalities and we get
    \[p(x)  = p(x+n) + p(n) = p(x+n).\]
    Thus, $p(x) = 0 \implies x \in N$. But, $x \in \hat{x}$, which means that $\hat{x} = N$, and hence, $\hat{x}$ is the zero element of $X/N$. This is easy to see. Assume $\hat{y} = y + N$ and $\hat{x} = x + N$, where $x \in N$. Then, $\hat{x} + \hat{y} = (x + y) + N = y + N$ since $x + N = N$.
\end{proof}

\begin{question}
    Let $Y$ be a closed subspace of a normed space $(X , \norm{.})$. Show that a norm $\norm{.}$ on $X/Y$ is defined by 
    \[\norm{\hat{x}}_0 = \inf_{x \in \hat{x}} \norm{x}\]
    where $\hat{x} \in X/Y$, i.e, $\hat{x}$ is any coset of $Y$.
    \label{section2.3-14}
\end{question}
\begin{proof}
    Clearly, $\norm{\hat{x}}_0$ is non-negative. Also, if $\hat{x} = Y$, which is the zero element of $X/Y$, then
    \[\norm{\hat{x}}_0 = \norm{Y}_0 = \inf_{y \in Y} \norm{y} = 0\]
    since $Y$ is a closed subspace, $0 \in Y$. Also, if $\norm{\hat{x}}_0 = 0$, then
    \[\norm{\hat{x}}_0 = 0 = \inf_{x \in \hat{x}} \norm{x} \implies \exists x \in \hat{x} \text{ such that } \norm{x} = 0 \implies x = 0 \implies \hat{x} = Y.\]
    where the second to last implication follows since $\norm{.}$ is a valid norm. Now, 
    \[\norm{\alpha \hat{x}}_0 = \inf_{x \in \alpha \hat{x}} \norm{x} = \inf_{x \in \hat{x}} \norm{\alpha x} = \abs{\alpha} \inf_{x \in \hat{x}} \norm{x} = \abs{\alpha} \norm{\hat{x}}_0.\]
    Finally, suppose $\hat{x} = x + Y$ and $\hat{y} = y + Y$, then
    \[\hat{x} + \hat{y} = (x+y) + Y.\]
    Thus, 
    \[\norm{\hat{x} + \hat{y}}_0 = \inf_{a \in \hat{x} + \hat{y}} \norm{a} = \inf_{x \in \hat{x} , y \in \hat{y}} \norm{x + y} \leq \inf_{x \in \hat{x} , y \in \hat{y}} \norm{x} + \inf_{x \in \hat{x} , y \in \hat{y}} \norm{y} = \inf_{x \in \hat{x}} \norm{x} + \inf_{y \in \hat{y}} \norm{y} = \norm{\hat{x}}_0 + \norm{\hat{y}}_0.\]
   Thus, it is a valid norm.
\end{proof}

\begin{question}
    If $(X_1 , \norm{.}_1)$ and $(X_2 , \norm{.}_2)$ are normed spaces, show that the product vector space $X = X_1 \times X_2$ becomes a normed space if
    \[\norm{x} = \max\{\norm{x_1}_1 , \norm{x_2}_2\}.\]
    \label{section2.3-15}
\end{question}
\begin{proof}
    Clearly, for $x = (x_1 , x_2)$, $\norm{x} \geq 0$. Also, if $x = (0,0)$, then $\norm{x} = 0$. Also, if $\norm{x} = 0$, then both $\norm{x_1}_1 = 0$ and $\norm{x_2}_2 = 0$, resulting in $x = 0$. Now, 
    \[\norm{\alpha x} = \max\{\norm{\alpha x_1}_1 , \norm{\alpha x_2}_2\} = \abs{\alpha} \max\{\norm{x_1}_1 , \norm{x_2}_2\} = \abs{\alpha} \norm{x}.\]
    Finally, 
    \[\norm{x + y} = \max\{\abs{x_1 + y_1} , \abs{x_2 + y_2}\} = \abs{x_j + y_j} \leq \abs{x_j} + \abs{y_j} \leq \max\{\abs{x_1} , \abs{x_2}\} + \max\{\abs{y_1} + \abs{y_2}\} = \norm{x} + \norm{y}\]
    Thus, it is a valid norm.
\end{proof}